import numpy as np 
import open3d as o3d 
from typing import Tuple, Optional

def depth_to_camera_frame_point_cloud(
        depth: np.ndarray, 
        K: np.ndarray, 
        rgb: Optional[np.ndarray] = None,      
) -> Tuple[np.ndarray, Optional[np.ndarray]]:
    
    """the goal of this script is to take the rdgbd inputs that are generated by the extrinsics/intrinsics of the camera
    and make them into 3d point clouds
    [u]  [fx 0 cx]    [x]
    [v] = [0 fy cy] * [y]
    [1]  [0 0 1]      [z]

    where the u, v are in pixel space and the xyz are 3d space so this is the inverse function from the projection     
    x = (u - cx)*z / fx 
    y = (u - cy)*z / fy
    z = depth 

    inputs are depth = (H, W)
    K = camera intrinsics matrix 
    rgb = optional rgb image of shape (H, W, 3) in [0, 1]

    returns points of shape (N, 3) where N = H * W 
    colors = optional array of colors
    """

    H, W = depth.shape 
    
    # create pixel coordinate grids (u is horizontal and v is vertical)
    u, v = np.meshgrid(np.arange(W). np.arange(H))

    # extract the camera intrinsics 
    fx, fy = K[0, 0], K[1, 1]
    cx, cy = K[0, 2], K[1, 2]

    # inverse projection for each pixel at once 
    z = depth 
    x = (u - cx) * z / fx
    y = (u - cy) * z / fy

    # now x, y, z are all (H, W) arrays 
    # stack them vertically and reshape to (H*W, 3)
    points = np.stack([x,y,z], axis=-1) # shape is ()

    # np.stack() creates a new dimension to add on 
    # hence the points is (h, w, 3) since it stacked 3 arrays 
    points.reshape(-1, 3) # shape is now (H*W, 3)
    # flatten for a list of points so that it can be indexed as point[k] = [x, y, z] for the kth point 

    colors = None 
    if rgb is not None:
        colors = rgb.reshape(-1, 3) # (H*W, 3) to match points 
    return points, colors





