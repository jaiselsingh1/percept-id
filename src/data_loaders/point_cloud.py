import numpy as np
import open3d as o3d
from typing import Tuple, Optional

def depth_to_camera_frame_point_cloud(
    depth: np.ndarray,
    K: np.ndarray,
    rgb: Optional[np.ndarray] = None,
) -> Tuple[np.ndarray, Optional[np.ndarray]]:
    """the goal of this script is to take the rgbd inputs that are generated by the extrinsics/intrinsics of the camera
    and make them into 3d point clouds
    [u]   [fx  0 cx]   [x]
    [v] = [ 0 fy cy] * [y]
    [1]   [ 0  0  1]   [z]

    where the u, v are in pixel space and the xyz are 3d space so this is the inverse function from the projection
    x = (u - cx)*z / fx
    y = (v - cy)*z / fy
    z = depth

    inputs are depth = (H, W)
    K = camera intrinsics matrix
    rgb = optional rgb image of shape (H, W, 3) in [0, 1]

    returns points of shape (N, 3) where N = H * W
    colors = optional array of colors
    """
    H, W = depth.shape

    # create pixel coordinate grids (u is horizontal and v is vertical)
    u, v = np.meshgrid(np.arange(W), np.arange(H))

    # extract the camera intrinsics
    fx, fy = K[0, 0], K[1, 1]
    cx, cy = K[0, 2], K[1, 2]

    # inverse projection for each pixel at once
    z = depth
    x = (u - cx) * z / fx
    y = (v - cy) * z / fy

    # now x, y, z are all (H, W) arrays
    # stack them vertically and reshape to (H*W, 3)
    points = np.stack([x, y, z], axis=-1)  # shape is (H, W, 3)

    # np.stack() creates a new dimension to add on
    # hence the points is (h, w, 3) since it stacked 3 arrays
    points = points.reshape(-1, 3)  # shape is now (H*W, 3)
    # flatten for a list of points so that it can be indexed as point[k] = [x, y, z] for the kth point

    colors = None
    if rgb is not None:
        colors = rgb.reshape(-1, 3)  # (H*W, 3) to match points

    return points, colors


def transform_points_to_world(
    points: np.ndarray,
    camera_T_world: np.ndarray
) -> np.ndarray:
    """Transform points from camera frame to world frame using extrinsics.

    camera_T_world transforms FROM world TO camera, so we invert it.

    Args:
        points: (N, 3) points in camera frame
        camera_T_world: 4x4 transform from world to camera (extrinsics)

    Returns:
        (N, 3) points in world frame
    """
    N = points.shape[0]
    world_T_camera = np.linalg.inv(camera_T_world)

    # numpy's inv() knows how to handle the special cases of transformation matrices
    # next convert to homogeneous coordinates

    ones = np.ones((N, 1))
    # hstack() stacks arrays horizontally so across columns

    points_hom = np.hstack([points, ones])
    # each of the points now has a 1 at the end of it being in homogeneous coordinates

    points_hom_T = points_hom.T
    points_hom_world_T = world_T_camera @ points_hom_T

    points_hom_world = points_hom_world_T.T

    # extract the 3D coordinates aka bring it back from being homogeneous
    points_world = points_hom_world[:, :3]

    return points_world


def create_point_cloud_from_rgbd(
    rgb: np.ndarray,
    depth: np.ndarray,
    K: np.ndarray,
    camera_T_world: np.ndarray,
    segmentation_mask: Optional[np.ndarray] = None,
    filter_invalid: bool = True,
    bbox: Optional[np.ndarray] = None,
) -> o3d.geometry.PointCloud:
    """Create point cloud from RGB-D with optional segmentation mask filtering"""

    points_cam, colors = depth_to_camera_frame_point_cloud(depth, K, rgb)
    points = transform_points_to_world(points_cam, camera_T_world)

    # Flatten segmentation mask if provided (H, W) -> (H*W,)
    if segmentation_mask is not None:
        seg_mask_flat = segmentation_mask.reshape(-1)
    else:
        seg_mask_flat = np.ones(points.shape[0], dtype=bool)  # All points valid

    # Filter invalid points (where depth <= 0)
    if filter_invalid:
        depth_flat = depth.reshape(-1)
        valid_mask = depth_flat > 0

        points = points[valid_mask]
        colors = colors[valid_mask]
        seg_mask_flat = seg_mask_flat[valid_mask]  # Apply same filtering to mask

    # Filter by bounding box if provided
    if bbox is not None:
        bbox_min = bbox[0]
        bbox_max = bbox[1]

        x_in_range = (points[:, 0] >= bbox_min[0]) & (points[:, 0] <= bbox_max[0])
        y_in_range = (points[:, 1] >= bbox_min[1]) & (points[:, 1] <= bbox_max[1])
        z_in_range = (points[:, 2] >= bbox_min[2]) & (points[:, 2] <= bbox_max[2])

        bbox_mask = x_in_range & y_in_range & z_in_range
        points = points[bbox_mask]
        colors = colors[bbox_mask]
        seg_mask_flat = seg_mask_flat[bbox_mask]  # Apply same filtering to mask

    # Filter by segmentation mask
    points = points[seg_mask_flat]
    colors = colors[seg_mask_flat]

    pcd = o3d.geometry.PointCloud()
    pcd.points = o3d.utility.Vector3dVector(points.astype(np.float64))
    pcd.colors = o3d.utility.Vector3dVector(colors.astype(np.float64))

    return pcd


# def create_point_cloud_from_rgbd(
#     rgb: np.ndarray,
#     depth: np.ndarray,
#     K: np.ndarray,
#     world_T_camera: np.ndarray,
#     filter_invalid: bool = True,
#     bbox: Optional[np.ndarray] = None
# ) -> o3d.geometry.PointCloud:
#     """The goal of this function is to use the above functions and create the point clouds"""

#     points_cam, colors = depth_to_camera_frame_point_cloud(depth, K, rgb)
#     points = transform_points_to_world(points_cam, world_T_camera)

#     # Filter invalid points (where depth <= 0)
#     if filter_invalid:
#         depth_flat = depth.reshape(-1)
#         valid_mask = depth_flat > 0

#         points = points[valid_mask]
#         colors = colors[valid_mask]

#     # Filter by bounding box if provided
#     # the bbox here is an axis alligned bounding box
#     if bbox is not None:
#         bbox_min = bbox[0]
#         bbox_max = bbox[1]

#         x_in_range = (points[:, 0] >= bbox_min[0]) & (points[:, 0] <= bbox_max[0])
#         y_in_range = (points[:, 1] >= bbox_min[1]) & (points[:, 1] <= bbox_max[1])
#         z_in_range = (points[:, 2] >= bbox_min[2]) & (points[:, 2] <= bbox_max[2])

#         bbox_mask = x_in_range & y_in_range & z_in_range
#         points = points[bbox_mask]
#         colors = colors[bbox_mask]

#     pcd = o3d.geometry.PointCloud()
#     # the pcd is a c++ wrapper in python which needs (N, 3) for the point's 3D positions 
#     # the pcd.colors is RGB colors 
#     pcd.points = o3d.utility.Vector3dVector(points.astype(np.float64))
#     pcd.colors = o3d.utility.Vector3dVector(colors.astype(np.float64))

#     return pcd


